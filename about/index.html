
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
        <link rel="next" href="../unet/">
      
      
        
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>E3tts - E3TTS</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.484c7ddc.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#introduction" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="E3TTS" class="md-header__button md-logo" aria-label="E3TTS" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            E3TTS
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              E3tts
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
  
    
  
  E3tts

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../unet/" class="md-tabs__link">
        
  
  
    
  
  UNet

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="E3TTS" class="md-nav__button md-logo" aria-label="E3TTS" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    E3TTS
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    E3tts
  

    
  </span>
  
  

      </a>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../unet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    UNet
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="introduction">Introduction</h1>
<p>Over past years, I have been exploring about Text-to-Speech models, which takes plain text as input and generates audio waveform. There are a lot of models for converting plain text into speech. To understand how text is converted into speech, we need to understand how text and speech is represented.</p>
<p>There are different approach in which we can handle text and same goes for speech. For text, we can use text as raw input without any processing or can convert raw text into phonemes and then feed into the model. Module to convert text to phoneme can be helpful to embed different language specific pronunciation details. </p>
<p>Audio data is represented in waveform format. Audio data can be represented in different forms. For working with TTS models, I have majorly dealt with audio waveform which represents audio in time dimension and Mel-Spectrogram which represents audio in frequency domain.</p>
<h1 id="approach">Approach</h1>
<p>For building TTS model, there are different approach. Models can be categorised based on the approach with which it is converting the text into speech. For example, early models first convert the text into Mel-Spectrogram. Then vocoder models are used to convert the Mel-Spectrogram to wavefrom, basically converting frequency domain data into time domain. Converting text into audio speech is sequence to sequence problem statement. With early models, there were different aspects for creating training data. TTS models were dependent on text to audio time-frames alignment data. Mapping of a text token/phoneme to the time frame which audio waveform/mel-spectrogram belongs. </p>
<p>As we move along the time, in hope of building TTS models which could generate speech of high fidelity, which would capture complex nuances of mapping text tokens to audio frames End-to-End models were developed. These End-to-End models would just take plain text/phonemes as input and will generate audio wavefrom directly. It's architecture are designed as such, it will learn the alignment between text and audio frames while training process. Enough talking is done, let's deep dive into the model, which I am planning to create from scratch. It is different from above mention approach. It is based on diffusion model architecture along with text information coming from BERT model embedding.</p>
<h1 id="e3tts">E3TTS</h1>
<p>E3TTS is <strong>E</strong>asy <strong>End</strong>-to-<strong>E</strong>nd Diffusion based text to speech, a simple and efficient model. It takes plain text and generates an audio waveform through an iterative process of refinement. Unlike many TTS models, this does not rely on any intermediate representations like spectrogram features or alignment information. Instead E3TTS models the temporal structure of the waveform through the diffusion process. Without relying on additional conditioning information, E3 TTS could support flexible latent structure within the given audio. This enables E3 TTS to be easily adapted for zero-shot tasks such as editing without any additional training.</p>
<p><img alt="UNet Diagram" src="../img/e3tts_model_diagram.png" />
<center><i>UNet Structure: DBlock for downsampling block, UBlock for upsampling block</i></center></p>
<p>To understand the building blocks of E3-TTS, we need to understand few concepts like Adaptive kernel for CNN layer, FiLM and Efficient UNet.</p>
<h1 id="adaptive-kernel">Adaptive kernel</h1>
<p>Standard convolution layer works with static kernel which is initialized at start of the training. As training progresses the weights of kernel are updated via backpropagation. Convolution layers came out to be very effective to capture the features of spatial data (images) or sequential data of large sequence (audio data). The behavior of static kernel tends to be very rigid compared to dynamic kernels which are generated on the fly while training. Adaptive kernels have advantage over static kernels like:</p>
<ol>
<li>
<p><strong>Context Sensitivity</strong>: The model can change its processing strategy based on the speaker identity. For example, the filter used to generate a high-pitched child's voice should be different from one used for a deep baritone voice.</p>
</li>
<li>
<p><strong>Parameter Efficiency</strong>: Instead of learning 100 different static filters to handle 100 different scenarios, you learn one small "generator" network that creates the right filter for the right moment.</p>
</li>
<li>
<p><strong>Temporal Precision</strong>: In diffusion models (like E3TTS), the noise level changes at every step. Adaptive kernels allow the network to adjust its "denoising strength" precisely according to the time-step <span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span>, smoothing out noise aggressively in early steps and preserving fine details in later steps.</p>
</li>
</ol>
<h2 id="implementation">Implementation</h2>
<p>Adaptive kernel is used in E3TTS model conditioned with time and speaker embedding. Let's assume the embedding dimensions of time and speaker to be <code>128</code> and <code>256</code> respectively.</p>
<ul>
<li>Time embedding: <span class="arithmatex"><span class="MathJax_Preview">t \in \mathbb{R}^{128}</span><script type="math/tex">t \in \mathbb{R}^{128}</script></span></li>
<li>Speaker embedding: <span class="arithmatex"><span class="MathJax_Preview">s \in \mathbb{R}^{256}</span><script type="math/tex">s \in \mathbb{R}^{256}</script></span></li>
<li>Condition embedding: <span class="arithmatex"><span class="MathJax_Preview">c \in \mathbb{R}^{384}</span><script type="math/tex">c \in \mathbb{R}^{384}</script></span></li>
</ul>
<p>Condition embedding is created by concatenating the time and speaker embedding by last dimension</p>
<pre><code class="language-python">condition = torch.cat([t, s], dim=-1)
</code></pre>
<p>To create adaptive kernels for convolution layer, we need to create <code>N</code> bank of kernel basis and <code>N</code> mixin-weights. For weights, we pass the condition vector <code>c</code> through affine network and softmax activation. This gives the weights which will be used to sum kernel basis. Kernel basis can be initialized with the shape of <code>(n_basis, out_channel, in_channel, kernel_size)</code></p>
<pre><code class="language-python"># Affine Network
affine_network = nn.Sequential(
    nn.Linear(time_embedding_dims + speaker_embedding_dims, n_basis),
    nn.Softmax(dim=-1)
)

# Basis Kernels
basis_kernels = nn.Parameter(
    torch.randn(n_basis, out_channels, in_channels, kernel_size)
)
</code></pre>
<p>Affine layer calculates the logits from condition vector. 
$$
weights = \text{Softmax}(w^T*c + b);\quad Where \;weights\in   [0, 1]^{n_{\text{basis}}} 
\\
\text{basis_kernels}\in\mathbb{R}^{n_{\text{basis}}\times\text{out_channels}\times\text{in_channels}\times\text{kernel_size}}
$$
Based on these weights, basis kernels are summed to calculate the adaptive kernel which will be used to convolution layer.</p>
<pre><code class="language-python">kernel = torch.einsum(
    'bn,noik-&gt;boik',
    weights,
    basis_kernels
)
</code></pre>
<p>Below is the full implementation of Adaptive Kernel along with Adaptive Convolution layer module in PyTorch:</p>
<pre><code class="language-python">class AdaptiveKernel(nn.Module):

    def __init__(self, n_basis, in_channels, out_channels, kernel_size, time_embedding_dim, speaker_embedding_dim):
        super(AdaptiveKernel, self).__init__()
        self.n_basis = n_basis
        self.time_embedding_dim = time_embedding_dim
        self.speaker_embedding_dim = speaker_embedding_dim
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size

        # Defining the Affine Network
        self.affine_network = nn.Sequential(
            nn.Linear(self.time_embedding_dim + self.speaker_embedding_dim, self.n_basis),
            nn.Softmax(dim=-1)
        )

        # Define the basis filters
        # N number of kernels of shape (in_channels, out_channels, kernel_size)
        self.basis_kernels = nn.Parameter(
            torch.randn(self.n_basis, self.out_channels, self.in_channels, self.kernel_size)
        )


    def forward(self, time_embedding, speaker_embedding):
        &quot;&quot;&quot;
        Args:
            time_embedding: Tensor of shape (B, time_embedding_dim)
            speaker_embedding: Tensor of shape (B, speaker_embedding_dim)
        Returns:
            Tensor of shape (B, out_channels, in_channels, kernel_size)
        &quot;&quot;&quot;
        condition = torch([time_embedding, speaker_embedding], dim=-1)

        mix_weights = self.affine_network(condition)

        adaptive_kernel = torch.einsum(
            'bn,noik-&gt;boik',
            mix_weights,
            self.basis_kernels
        )

        return adaptive_kernel


class AdaptiveConv1D(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, time_embedding_dim, speaker_embedding_dim, n_basis=8):
        super(AdaptiveConv1D, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.time_embedding_dim = time_embedding_dim
        self.speaker_embedding_dim = speaker_embedding_dim
        self.n_basis = n_basis
        self.adaptive_kernel = AdaptiveKernel(self.n_basis, self.in_channels, self.out_channels, self.kernel_size, self.time_embedding_dim, self.speaker_embedding_dim)

    def forward(self, x, time_embedding, speaker_embedding):
        &quot;&quot;&quot;
        Args:
            x: Tensor of shape (B, in_channels, L)
            time_embedding: Tensor of shape (B, time_embedding_dim)
            speaker_embedding: Tensor of shape (B, speaker_embedding_dim)
        Returns:
            Tensor of shape (B, out_channels, L)
        &quot;&quot;&quot;
        kernel = self.adaptive_kernel(time_embedding, speaker_embedding)
        return F.conv1d(x, kernel, stride=1, padding=self.kernel_size // 2)
</code></pre>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "..", "features": ["navigation.tabs", "navigation.top", "search.highlight", "search.suggest", "toc.integrate", "content.code.annotate", "content.code.copy", "content.tabs.link"], "search": "../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>